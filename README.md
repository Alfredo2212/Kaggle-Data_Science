Kaggle Data Science Project
--
Welcome to my Kaggle Data Science project repository !
This collection showcases end-to-end solutions to real-world problems tackled 
through Kaggle competitions. Each notebook demonstrates a complete workflowâ€”from 
exploratory data analysis and preprocessing to model training and evaluation.

## 1. Titanic - Survival Prediction
**Models used**: Random Forest, XGBoost  
**Highlights**:
- Data cleaning and imputation
- Feature engineering (e.g., Title extraction, Cabin simplification)
- Handling class imbalance
- Hyperparameter tuning
- Model ensembling for final prediction

## 2. House Price Prediction
**Models used**: Ridge regression, XGBoost  
**Highlights**:
- Extensive data cleaning and missing value imputation
- Advanced feature engineering (e.g., label encoding, skew correction)
- Outlier detection and removal for improved generalization
- Comparison of baseline models vs regularized regressors
- Final ensemble blending ridge + XGBoost for better predictive performance

